{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Classical Quantum AutoEncoder for anomaly detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VQC\n",
    "The VQC implemented is the number 10 of the reference paper, which essentially is a stack Pauli $YX$ rotation gate and a circular series of controlled $CX$, stacked while alternated with an encoding based on the Pauli $X$ rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import QuantumCircuit, Gate, ParameterVector\n",
    "from qiskit.opflow.expectations import PauliExpectation\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "def get_encoding_block(nqubits: int, features: ParameterVector) -> Gate:\n",
    "    \"\"\" n parameters required \"\"\"\n",
    "    assert len(features) == nqubits \n",
    "    block = QuantumCircuit(nqubits, name=\"Encoding Block\")\n",
    "    for i in range(nqubits):\n",
    "        block.rx(features[i], i)\n",
    "    return block.to_gate()\n",
    "\n",
    "def get_ansatz_block(nqubits: int, parameters: ParameterVector) -> Gate:\n",
    "    \"\"\"\n",
    "    need 2n parameters\n",
    "    \"\"\"\n",
    "    assert nqubits * 2 == len(parameters)\n",
    "    block = QuantumCircuit(nqubits, name=\"Ansatz Block\")\n",
    "    for i in range(nqubits):\n",
    "        block.ry(parameters[i], i)\n",
    "        block.rx(parameters[i + nqubits], i)\n",
    "    if nqubits > 1:\n",
    "        block.cx(nqubits - 1, 0)\n",
    "        for i in range(nqubits - 1):\n",
    "            block.cx(i, i + 1)\n",
    "    return block.to_gate()\n",
    "\n",
    "def get_ansatz(nqubits: int, parameters: ParameterVector, features: ParameterVector, reps: int=3) -> QuantumCircuit:\n",
    "    assert len(parameters) == reps * 2 * nqubits\n",
    "    ansatz = QuantumCircuit(nqubits)\n",
    "    ansatz.compose(get_ansatz_block(nqubits, parameters[:2 * nqubits]), range(nqubits), inplace=True)\n",
    "    for i in range(1, reps):\n",
    "        ansatz.barrier()\n",
    "        ansatz.compose(get_encoding_block(nqubits, features), range(nqubits), inplace=True)\n",
    "        ansatz.barrier()\n",
    "        ansatz.compose(get_ansatz_block(nqubits, parameters[2 * nqubits * i :2 * nqubits * (i + 1)]), range(nqubits), inplace=True)\n",
    "    return ansatz\n",
    "\n",
    "def get_ansatz_ws(nqubits: int, parameters: ParameterVector, features: ParameterVector, reps: int=3) -> QuantumCircuit:\n",
    "    assert len(parameters) == 2 * nqubits\n",
    "    ansatz = QuantumCircuit(nqubits)\n",
    "    ansatz.compose(get_ansatz_block(nqubits, parameters), range(nqubits), inplace=True)\n",
    "    for i in range(1, reps):\n",
    "        ansatz.barrier()\n",
    "        ansatz.compose(get_encoding_block(nqubits, features), range(nqubits), inplace=True)\n",
    "        ansatz.barrier()\n",
    "        ansatz.compose(get_ansatz_block(nqubits, parameters), range(nqubits), inplace=True)\n",
    "    return ansatz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.utils import algorithm_globals\n",
    "algorithm_globals.random_seed = 528491\n",
    "\n",
    "size = (10, 4)\n",
    "data = algorithm_globals.random.random(size)\n",
    "nqubits = data.shape[1]\n",
    "print(data, nqubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = ParameterVector(\"x\", data.shape[1])\n",
    "weights = ParameterVector(\"theta\", nqubits * 2)\n",
    "circuit_ws = get_ansatz_ws(nqubits, weights, input)\n",
    "circuit_ws.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_weights_ws = algorithm_globals.random.random(2 * nqubits)\n",
    "print(random_weights_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "\n",
    "sqnn_ws = SamplerQNN(\n",
    "    circuit=circuit_ws,\n",
    "    input_params=input,\n",
    "    weight_params=weights,\n",
    "    interpret=lambda x: \"{:b}\".format(x).count('1') % 2 == 0, # parity check\n",
    "    output_shape=2\n",
    ")\n",
    "print(sqnn_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_qnn_forward = sqnn_ws.forward(data[0], random_weights_ws) # require encoding + ansatz parameters, result is a ndarray\n",
    "print(f\"Forward pass result for SamplerQNN: {sampler_qnn_forward}. \\nShape: {sampler_qnn_forward.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = ParameterVector(\"x1\", data.shape[1])\n",
    "weights1 = ParameterVector(\"theta1\", nqubits * 2 * 3)\n",
    "circuit = get_ansatz(nqubits, weights1, input1)\n",
    "circuit.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity(x):\n",
    "    print(x, str(x), \"{:b}\".format(x), \"{:b}\".format(x).count('1') % 2)\n",
    "    return \"{:b}\".format(x).count('1') % 2\n",
    "\n",
    "def custom_interpret(x):\n",
    "    return \"{:b}\".format(x).count('1') % 4\n",
    "\n",
    "\n",
    "sqnn = SamplerQNN(\n",
    "    circuit=circuit,\n",
    "    input_params=input1,\n",
    "    weight_params=weights1,\n",
    "    interpret=lambda x: custom_interpret(x), # parity check\n",
    "    output_shape=4\n",
    ")\n",
    "print(sqnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_weights = algorithm_globals.random.random(len(weights1))\n",
    "sampler_qnn_forward = sqnn.forward(data[0], random_weights) # require encoding + ansatz parameters, result is a ndarray\n",
    "print(f\"Forward pass result for SamplerQNN: {sampler_qnn_forward}. \\nShape: {sampler_qnn_forward.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.opflow.expectations import PauliExpectation\n",
    "\n",
    "def get_Z_expectation_qubitwise(nqubits: int) -> list:\n",
    "    \"\"\"\n",
    "        :nqubits\n",
    "        the number of qubits to evaluate\n",
    "        :return\n",
    "        the qubitwise observables for each Z expectation value, which follows the formula P(1) = (1 - Exp) / 2\n",
    "    \"\"\"\n",
    "    obs = []\n",
    "    for i in range(nqubits):\n",
    "        string = \"I\" * i + \"Z\" + \"I\" * (nqubits - (i + 1))\n",
    "        obs.append(SparsePauliOp.from_list([(string, 1)]))\n",
    "    return obs\n",
    "\n",
    "ob = get_Z_expectation_qubitwise(4)\n",
    "print(ob)\n",
    "\n",
    "# observable1 = SparsePauliOp.from_list([(\"Z\", 1), (\"Z\", 1), (\"Z\", 1), (\"I\", 1)])\n",
    "eqnn_ws = EstimatorQNN(\n",
    "    circuit=circuit_ws,\n",
    "    input_params=input,\n",
    "    weight_params=weights,\n",
    "    observables=ob\n",
    ")\n",
    "\n",
    "print(eqnn_ws)\n",
    "circuit_ws.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = eqnn_ws.forward(data[0], random_weights_ws)\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic AutoEncoder Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class HAE(nn.Module):\n",
    "    \"\"\"\n",
    "        general structure is:\n",
    "        - encoder, FC input_size -> 54 -> 4\n",
    "        - qnn\n",
    "        - decoder, FC 4 -> 54 -> input_size\n",
    "        - tanh activations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, qnn, input_size: int, nqubits: int = 4) -> None:\n",
    "        super(HAE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 54),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(54, nqubits),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.vqc = TorchConnector(qnn)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(nqubits, 54),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(54, input_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.encoder(X)\n",
    "        X = self.vqc(X)\n",
    "        X = (torch.ones_like(X) - X) / 2\n",
    "        X = self.decoder(X)\n",
    "        return X\n",
    "    \n",
    "    def encode(self, X):\n",
    "        return self.vqc(self.encode(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ins = 160\n",
    "input = torch.rand(ins)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = HAE(eqnn_ws, input_size=ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward = test(input)\n",
    "print(forward)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Training & Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    mse = nn.MSELoss()\n",
    "    model.eval()\n",
    "    avg_error = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(data_loader, desc=\"Validating\", leave=False):\n",
    "            X = X.to(device)\n",
    "            reconstruction = model(X)\n",
    "            avg_error += mse(reconstruction, X).sum().item() / len(X)\n",
    "    return avg_error\n",
    "\n",
    "def training(model, train_dl, val_dl, epochs: int = 100):\n",
    "    mse = nn.MSELoss()\n",
    "    optim = Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    for i in range(1, epochs + 1):\n",
    "        for X, y in tqdm(train_dl, \"Epoch #{}\".format(i), leave=True):\n",
    "            X = X.to(device)\n",
    "            reconstruction = model(X)\n",
    "            loss = mse(reconstruction, X)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        # if i % 5 == 0:\n",
    "        rec_error = evaluate(model, val_dl)\n",
    "        print(\"Validation average reconstruction error: {}\".format(rec_error))\n",
    "        model.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Define a random dataset and the arrhytmia dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import numpy as np\n",
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, size, length, mean = 0, std_dev = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.values = torch.normal(mean, std_dev, size=(length, size))\n",
    "        self.labels = (torch.normal(0, 1, size=(length,)) > 0) * 1\n",
    "        self.labels.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        X = self.values[idx]\n",
    "        y = self.labels[idx]\n",
    "        return X, y\n",
    "    \n",
    "random_data = RandomDataset(160, 1000, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class ArrythmiaDS(Dataset):\n",
    "\n",
    "    def __init__(self, path: str = \"./datasets/arrhythmia.data\", get_anomalies: bool = False) -> None:\n",
    "\n",
    "        def _is_nominal(df, idx) -> bool:\n",
    "            l = df.iloc[:, idx]\n",
    "            return len(l) == len(l[l == 0]) + len(l[l == 1])\n",
    "    \n",
    "        def _fix_missing(df: pd.DataFrame):\n",
    "            for i in range(len(df.columns)):\n",
    "                mean_value = df.iloc[:, i].mean(skipna=True)\n",
    "                if _is_nominal(df, i):\n",
    "                    # the mean is the bernoulli probability\n",
    "                    df.iloc[:, i].map(lambda x: x if x is not pd.NA else 1 * (np.random.random(mean_value) > 0.5))\n",
    "                else:\n",
    "                    pass\n",
    "                    df.iloc[:, i].fillna(value=mean_value, inplace=True)\n",
    "            return df\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(path, sep=',', na_values='?', dtype=np.float32)\n",
    "        self.labels = self.data.iloc[:, -1]\n",
    "        self.data = self.data.iloc[:, :-1]\n",
    "        self.data = _fix_missing(self.data)\n",
    "\n",
    "        # get normal data or anomalies\n",
    "        if not get_anomalies:\n",
    "            self.data = self.data[self.labels == 1] \n",
    "            self.labels = self.labels[self.labels == 1] \n",
    "        else:\n",
    "            self.data = self.data[self.labels != 1] \n",
    "            self.labels = self.labels[self.labels != 1] * 0 # use label = 0 as a generic indicator of anomaly\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data.iloc[idx, :]), torch.tensor(self.labels.iloc[idx])\n",
    "    \n",
    "\n",
    "def get_splits(dataset, dataset_anomalies, test_split: float = 0.3, validation_split: float = 0.3, batch_size: int = 64) -> tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    I = np.random.permutation(len(dataset))\n",
    "    Ian = np.random.permutation(len(dataset_anomalies))\n",
    "    test_size = int(len(dataset) * test_split)\n",
    "    a_test_size = int(len(dataset_anomalies) * test_split)\n",
    "    train_val_size = int((len(dataset) - test_size) * validation_split)\n",
    "    a_train_val_size = int((len(dataset_anomalies) - a_test_size) * validation_split)\n",
    "    ds_test = Subset(dataset, I[:test_size]) + Subset(dataset_anomalies, Ian[:a_test_size])\n",
    "    ds_val = Subset(dataset, I[test_size: test_size + train_val_size]) + Subset(dataset_anomalies, Ian[a_test_size: a_test_size + a_train_val_size])\n",
    "    ds_train = Subset(dataset, I[test_size + train_val_size:])\n",
    "    return DataLoader(ds_train, batch_size=batch_size, shuffle=True), DataLoader(ds_val, batch_size=batch_size, shuffle=True), DataLoader(ds_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "ds = ArrythmiaDS()\n",
    "dsa = ArrythmiaDS(get_anomalies=True)\n",
    "dl = DataLoader(ds)\n",
    "train_dl, val_dl, test_dl = get_splits(ds, dsa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick test\n",
    "We will only use two qubits as latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dl))\n",
    "print(train_features.shape, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.primitives import Estimator\n",
    "reps = 3\n",
    "weights = ParameterVector(\"w\", 8 * reps) # 2n * reps\n",
    "inputs = ParameterVector(\"x\", 4) # n\n",
    "qnn_circuit = get_ansatz(4, parameters=weights, features=inputs, reps=reps)\n",
    "qnn = EstimatorQNN(\n",
    "    circuit=qnn_circuit,\n",
    "    input_params=inputs,\n",
    "    weight_params=weights,\n",
    "    input_gradients=True,\n",
    "    observables=get_Z_expectation_qubitwise(4),\n",
    "    estimator=Estimator(options={'shots': 20})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hae = HAE(qnn, 279, nqubits=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(hae, train_dl, val_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(hae.state_dict(), \"weights/hae_3reps.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.load(\"weights/hae_3reps.pt\")\n",
    "print(type(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hae.load_state_dict(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(hae, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(test_dl):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
